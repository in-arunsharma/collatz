# V1.1 Performance Analysis

## V1.0 → V1.1 Comparison

### Throughput Improvement
- **V1.0:** 1,219,512 numbers/sec
- **V1.1:** 1,557,632 numbers/sec
- **Speedup:** 1.28x (28% faster)

### Execution Time
- **V1.0:** 820ms
- **V1.1:** 642ms
- **Improvement:** 1.28x faster

### Instructions Executed
- **V1.0:** 9.87 Billion
- **V1.1:** 8.44 Billion
- **Reduction:** 14% fewer instructions (better algorithm)

### CPU Cycles
- **V1.0:** 3.18 Billion
- **V1.1:** 2.71 Billion
- **Reduction:** 15% fewer cycles

### Instructions Per Cycle (IPC)
- **V1.0:** 3.10
- **V1.1:** 3.11
- **Change:** Consistent (still excellent)

### Branch Misses (THE BIG WIN)
- **V1.0:** 26.5 Million (1.52% miss rate)
- **V1.1:** 1.03 Million (0.065% miss rate)
- **Reduction:** 96% fewer branch misses
- **Improvement:** 23x better branch prediction

### Cache Performance
- **L1D Misses:** 113K → 86K (24% reduction)
- **LLC Misses:** 12.7K → 13.3K (similar)

---

## Key Wins

✅ **28% faster throughput** (1.22M → 1.56M nums/sec)

✅ **14% fewer instructions** - Algorithm is more efficient

✅ **96% fewer branch misses** - CTZ eliminates most if-checks in even-handling

✅ **Same step count (574.15)** - Mathematically equivalent algorithm

✅ **Clean hot path** - No prints in compute_collatz for better performance

---

## Why CTZ Works So Well

### V1.0 approach (slow):
```cpp
while (n % 2 == 0) {  // Multiple modulo checks
    n = n / 2;         // Multiple divisions
    steps++;           // Multiple iterations
}
```

### V1.1 approach (fast):
```cpp
int z = ctz_u128(n);   // One count-trailing-zeros instruction
if (z) {
    n >>= z;            // One shift operation
    steps += z;         // Count all steps at once
}
```

**Impact:**
- Eliminates loop iterations for even chains
- Replaces modulo (10-40 cycles) with bitwise AND (1 cycle)
- Replaces division (10-40 cycles) with bit shift (1 cycle)
- Dramatically reduces branch mispredictions

---

## Next Optimization Targets

Based on perf analysis:
1. Further reduce instructions (try loop unrolling)
2. Explore SIMD for parallel processing
3. OpenMP for multi-threading
4. Eventually: CUDA for MareNostrum GPUs

Current baseline for next version: **1.56M numbers/sec**
