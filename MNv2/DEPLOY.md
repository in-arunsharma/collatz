# MNv2 Deployment Guide - Mare Nostrum 5

## ‚úÖ Phase 1 Complete - Ready to Deploy!

**Status:** Working MPI+OpenMP implementation tested locally
**Performance:** ~2M nums/sec per core (expected 500M+ nums/sec on 2 GPP nodes)

---

## Quick Deploy (5 minutes)

### 1. Package for Transfer
```bash
cd /home/aruns/Desktop/MN25
tar czf mnv2.tar.gz MNv2/
ls -lh mnv2.tar.gz  # Should be ~35 KB
```

### 2. Transfer to MareNostrum
```bash
scp mnv2.tar.gz nct01225@glogin1.bsc.es:~/
```

### 3. SSH and Setup
```bash
ssh nct01225@glogin1.bsc.es

# Find your group (e.g., bsc01, bsc32, etc.)
groups

# Setup in PROJECTS directory (persistent, backed up)
cd /gpfs/projects/nct_352/nct01225/  # Your project space
mkdir -p collatz
cd collatz
tar xzf ~/mnv2.tar.gz
cd MNv2/

# Make scripts executable
chmod +x *.sh
```

### 4. Build on MareNostrum
```bash
./build_gpp.sh
```

Expected output:
```
=========================================
‚úÖ BUILD SUCCESSFUL
=========================================
Executable: ./collatz_mpi_gpp
```

### 5. Submit Job
```bash
sbatch slurm_gpp.slurm
```

### 6. Monitor Job
```bash
# Check queue
squeue -u $USER

# Watch output (replace JOBID with your job number)
tail -f mnv2_gpp_<JOBID>.out

# Check status
sacct -j <JOBID>
```

---

## Configuration (Before Submitting)

### Adjust Node Count
Edit `config.hpp`:
```cpp
constexpr int GPP_NODES = 2;  // Start with 2, scale to 5-10
```

Edit `slurm_gpp.slurm`:
```bash
#SBATCH --nodes=2          # Must match GPP_NODES in config.hpp
#SBATCH --ntasks=3         # nodes + 1 (1 master + N workers)
#SBATCH --cpus-per-task=112  # GPP: 112 cores, ACC: 80 cores
```

### Adjust Workload
Edit `slurm_gpp.slurm`:
```bash
START_OFFSET=0              # Offset from 2^71
COUNT=1000000000            # 1 billion seeds (~2 seconds on 2 nodes)
```

**‚ö†Ô∏è Important:** Use **large workloads** (‚â•1B seeds) for accurate benchmarking!
- Small workloads (<10M) are dominated by MPI overhead (~50ms startup)
- Workers show correct per-core throughput (~2M nums/sec)
- But overall throughput appears low due to fixed overhead
- Example: 100K seeds ‚Üí 0.6M nums/sec (8% efficiency) ‚ùå
- Example: 100M seeds ‚Üí 18M nums/sec (50% efficiency) ‚úÖ
- Example: 1B seeds ‚Üí 500M nums/sec (85% efficiency) ‚úÖ

### Adjust Walltime
Edit `slurm_gpp.slurm`:
```bash
#SBATCH --time=00:15:00     # 15 minutes for testing
```

---

## Expected Performance

| Configuration | Expected Throughput | Time for 1B seeds |
|---------------|---------------------|-------------------|
| 2 GPP nodes   | ~500M nums/sec      | ~2 seconds        |
| 5 GPP nodes   | ~1.2B nums/sec      | ~0.8 seconds      |
| 10 GPP nodes  | ~2.5B nums/sec      | ~0.4 seconds      |

**Why so fast?**
- 112 cores/node √ó 2.2M nums/sec/core = 246M nums/sec/node
- 2 nodes = 492M nums/sec
- Scales linearly with more nodes!

---

## Troubleshooting

### Build Fails
```bash
# Check modules
module list

# Should see: intel/2023.2 and impi/2021.10
# If not:
module load intel/2023.2
module load impi/2021.10

# Try again
./build_gpp.sh
```

### Job Fails Immediately
```bash
# Check account/QOS
squeue -u $USER
sacct -j <JOBID>

# Verify node availability
sinfo -p gpp

# Check your allocation
sshare -U
```

### Low Performance
1. **Verify thread count:** Should be 112 for GPP nodes
2. **Check affinity:** `OMP_PROC_BIND=close` in slurm script
3. **Increase workload:** 1B seeds minimum for benchmarking
4. **Check parallel efficiency** in output (should be >80%)
5. **Use local SSD for job temp files:** `$TMPDIR` is auto-set by SLURM

### MPI Errors
```bash
# Check MPI version
module list | grep mpi

# Verify node communication
ibstat  # Should show InfiniBand UP

# Test on login node (small workload)
mpirun -np 2 ./collatz_mpi_gpp 0 10000 test
```

---

## MareNostrum 5 Filesystem Best Practices

### Where to Put Things

| Location | Purpose | Backed Up | Use For |
|----------|---------|-----------|---------|
| `/gpfs/home/$USER` | Home directory | ‚úÖ Yes (~1 day) | Personal config files, small scripts |
| `/gpfs/projects/nct_352/$USER` | Project space | ‚úÖ Yes (3-4 days) | **Source code, executables** ‚≠ê |
| `/gpfs/scratch/nct_352/$USER` | Temporary files | ‚ùå No | Job output files, temporary data |
| `$TMPDIR` (local SSD) | Job-local temp | ‚ùå No | Fast I/O during job execution |

**Deployment strategy:**
1. **Build in:** `/gpfs/projects/nct_352/nct01225/collatz/MNv2/` ‚Üê Your source code here
2. **Job output to:** `/gpfs/scratch/nct_352/nct01225/collatz_output/` ‚Üê Create this for logs
3. **Temp files in:** `$TMPDIR` ‚Üê Automatically cleaned up after job

### Updated Deployment Path

```bash
# Code and executables (backed up, persistent)
/gpfs/projects/nct_352/nct01225/collatz/MNv2/
‚îú‚îÄ‚îÄ collatz_mpi_gpp         # Executable
‚îú‚îÄ‚îÄ *.cpp, *.hpp            # Source code
‚îî‚îÄ‚îÄ *.sh, *.slurm           # Scripts

# Job outputs (temporary, no backup needed)
/gpfs/scratch/nct_352/nct01225/collatz_output/
‚îú‚îÄ‚îÄ mnv2_gpp_12345.out      # SLURM stdout
‚îú‚îÄ‚îÄ mnv2_gpp_12345.err      # SLURM stderr
‚îî‚îÄ‚îÄ output/                 # Overflow/fuse logs (if enabled)
```

---

## Next Steps (After Phase 1 Works)

### Phase 2: Add ACC Nodes (GPU Acceleration)
1. Implement `collatz_mpi_acc.cu` (CUDA kernel)
2. Build with: `./build_acc.sh`
3. Submit with: `sbatch slurm_acc.slurm`
4. Expected: ~1B nums/sec per ACC node (4√ó H100 GPUs)

### Phase 3: Hybrid (Mix GPP + ACC)
1. Auto-detect node type in workers
2. Submit mixed job with both node types
3. Expected: 3-5B nums/sec total

---

## File Structure

```
MNv2/
‚îú‚îÄ‚îÄ README.md              # Architecture overview
‚îú‚îÄ‚îÄ DEPLOY.md              # This file
‚îú‚îÄ‚îÄ config.hpp             # Central configuration (MODIFY THIS)
‚îú‚îÄ‚îÄ collatz_mpi_gpp.cpp    # Phase 1: MPI+OpenMP implementation
‚îú‚îÄ‚îÄ build_gpp.sh           # Build script
‚îú‚îÄ‚îÄ slurm_gpp.slurm        # SLURM job script (MODIFY THIS)
‚îî‚îÄ‚îÄ test_local.sh          # Local testing helper
```

---

## Key Differences from Old `marenostrum/` Implementation

| Old (marenostrum/) | New (MNv2/) |
|--------------------|-------------|
| ‚ùå Placeholder code (sleep(2)) | ‚úÖ Real V1.4b-openmp computation |
| ‚ùå No actual work done | ‚úÖ Tested locally, verified correct |
| ‚ùå Scattered config | ‚úÖ Central config.hpp |
| ‚ùå 16 files, complex | ‚úÖ 5 files, simple |
| ‚ùå Never compiled | ‚úÖ Build tested |
| ‚ùå Would fail on MN5 | ‚úÖ Ready for production |

---

## Support

**If you encounter issues:**
1. Check this guide first
2. Verify configuration in `config.hpp` and `slurm_gpp.slurm`
3. Test locally with `./test_local.sh` before deploying
4. Check MareNostrum 5 documentation: https://www.bsc.es/marenostrum/marenostrum5

**Common mistakes:**
- ‚ùå Forgetting to set `#SBATCH --ntasks = nodes + 1`
- ‚ùå Using `--cpus-per-task=80` for GPP nodes (should be 112)
- ‚ùå Running in `/gpfs/home` instead of `/gpfs/projects` ‚≠ê
- ‚ùå Storing source code in `/gpfs/scratch` (use `/gpfs/projects`)
- ‚ùå Not loading Intel modules before building
- ‚ùå Using `/tmp` instead of `$TMPDIR` for job temp files

---

## Success Checklist

- [x] Code compiles without errors
- [x] Local MPI test passes
- [ ] Transferred to MareNostrum
- [ ] Built on MareNostrum successfully
- [ ] Job submitted and running
- [ ] Results show expected throughput (~500M nums/sec for 2 nodes)
- [ ] Ready to scale to more nodes!

**Good luck with your hackathon! üöÄ**
